{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2536ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4383fc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"labeled.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "463f38fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14412, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b99b6818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    #pattern = [zero or more character]\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    \n",
    "    #pattern = with or without(http),://, one or more non-white space character, OR www, .,one or more non-white space character\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    #pattern = <, zero or more characters, >, (one or more occurance of >)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    \n",
    "    #pattern = any punctionation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    \n",
    "    #pattern = any new line\n",
    "    text = re.sub('\\n', '', text)\n",
    "    \n",
    "    #pattern = any from[a-zA-Z0-9_], any from[0-9], any from [a-zA-Z0-9_]\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73d3fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_text'] = train['comment'].apply(str).apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6c2ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>верблюдовто за что дебилы бл</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>хохлы это отдушина затюканого россиянина мол в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>собаке  собачья смерть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>страницу обнови дебил это тоже не оскорбление ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>тебя не убедил  пдф в том что скрипалей отрави...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>вонючий совковый скот прибежал и ноет а вот и ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14408</th>\n",
       "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>а кого любить гоблина тупорылого чтоли или как...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14409</th>\n",
       "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>посмотрел утомленных солнцем  и оказалось что ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14410</th>\n",
       "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>крымотред нарушает правила раздела тк в нем не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>до сих пор пересматриваю его видео орамбо кста...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic  \\\n",
       "0                   Верблюдов-то за что? Дебилы, бл...\\n    1.0   \n",
       "1      Хохлы, это отдушина затюканого россиянина, мол...    1.0   \n",
       "2                              Собаке - собачья смерть\\n    1.0   \n",
       "3      Страницу обнови, дебил. Это тоже не оскорблени...    1.0   \n",
       "4      тебя не убедил 6-страничный пдф в том, что Скр...    1.0   \n",
       "...                                                  ...    ...   \n",
       "14407  Вонючий совковый скот прибежал и ноет. А вот и...    1.0   \n",
       "14408  А кого любить? Гоблина тупорылого что-ли? Или ...    1.0   \n",
       "14409  Посмотрел Утомленных солнцем 2. И оказалось, ч...    0.0   \n",
       "14410  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...    1.0   \n",
       "14411  До сих пор пересматриваю его видео. Орамбо кст...    0.0   \n",
       "\n",
       "                                              clean_text  \n",
       "0                           верблюдовто за что дебилы бл  \n",
       "1      хохлы это отдушина затюканого россиянина мол в...  \n",
       "2                                 собаке  собачья смерть  \n",
       "3      страницу обнови дебил это тоже не оскорбление ...  \n",
       "4      тебя не убедил  пдф в том что скрипалей отрави...  \n",
       "...                                                  ...  \n",
       "14407  вонючий совковый скот прибежал и ноет а вот и ...  \n",
       "14408  а кого любить гоблина тупорылого чтоли или как...  \n",
       "14409  посмотрел утомленных солнцем  и оказалось что ...  \n",
       "14410  крымотред нарушает правила раздела тк в нем не...  \n",
       "14411  до сих пор пересматриваю его видео орамбо кста...  \n",
       "\n",
       "[14412 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ce95e",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "725ae4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>верблюдовто за что дебилы бл</td>\n",
       "      <td>[верблюдовто, за, что, дебилы, бл]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>хохлы это отдушина затюканого россиянина мол в...</td>\n",
       "      <td>[хохлы, это, отдушина, затюканого, россиянина,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>собаке  собачья смерть</td>\n",
       "      <td>[собаке, собачья, смерть]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>страницу обнови дебил это тоже не оскорбление ...</td>\n",
       "      <td>[страницу, обнови, дебил, это, тоже, не, оскор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>тебя не убедил  пдф в том что скрипалей отрави...</td>\n",
       "      <td>[тебя, не, убедил, пдф, в, том, что, скрипалей...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>вонючий совковый скот прибежал и ноет а вот и ...</td>\n",
       "      <td>[вонючий, совковый, скот, прибежал, и, ноет, а...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14408</th>\n",
       "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>а кого любить гоблина тупорылого чтоли или как...</td>\n",
       "      <td>[а, кого, любить, гоблина, тупорылого, чтоли, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14409</th>\n",
       "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>посмотрел утомленных солнцем  и оказалось что ...</td>\n",
       "      <td>[посмотрел, утомленных, солнцем, и, оказалось,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14410</th>\n",
       "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>крымотред нарушает правила раздела тк в нем не...</td>\n",
       "      <td>[крымотред, нарушает, правила, раздела, тк, в,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>до сих пор пересматриваю его видео орамбо кста...</td>\n",
       "      <td>[до, сих, пор, пересматриваю, его, видео, орам...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14412 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic  \\\n",
       "0                   Верблюдов-то за что? Дебилы, бл...\\n    1.0   \n",
       "1      Хохлы, это отдушина затюканого россиянина, мол...    1.0   \n",
       "2                              Собаке - собачья смерть\\n    1.0   \n",
       "3      Страницу обнови, дебил. Это тоже не оскорблени...    1.0   \n",
       "4      тебя не убедил 6-страничный пдф в том, что Скр...    1.0   \n",
       "...                                                  ...    ...   \n",
       "14407  Вонючий совковый скот прибежал и ноет. А вот и...    1.0   \n",
       "14408  А кого любить? Гоблина тупорылого что-ли? Или ...    1.0   \n",
       "14409  Посмотрел Утомленных солнцем 2. И оказалось, ч...    0.0   \n",
       "14410  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...    1.0   \n",
       "14411  До сих пор пересматриваю его видео. Орамбо кст...    0.0   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0                           верблюдовто за что дебилы бл   \n",
       "1      хохлы это отдушина затюканого россиянина мол в...   \n",
       "2                                 собаке  собачья смерть   \n",
       "3      страницу обнови дебил это тоже не оскорбление ...   \n",
       "4      тебя не убедил  пдф в том что скрипалей отрави...   \n",
       "...                                                  ...   \n",
       "14407  вонючий совковый скот прибежал и ноет а вот и ...   \n",
       "14408  а кого любить гоблина тупорылого чтоли или как...   \n",
       "14409  посмотрел утомленных солнцем  и оказалось что ...   \n",
       "14410  крымотред нарушает правила раздела тк в нем не...   \n",
       "14411  до сих пор пересматриваю его видео орамбо кста...   \n",
       "\n",
       "                                           clean_text_tk  \n",
       "0                     [верблюдовто, за, что, дебилы, бл]  \n",
       "1      [хохлы, это, отдушина, затюканого, россиянина,...  \n",
       "2                              [собаке, собачья, смерть]  \n",
       "3      [страницу, обнови, дебил, это, тоже, не, оскор...  \n",
       "4      [тебя, не, убедил, пдф, в, том, что, скрипалей...  \n",
       "...                                                  ...  \n",
       "14407  [вонючий, совковый, скот, прибежал, и, ноет, а...  \n",
       "14408  [а, кого, любить, гоблина, тупорылого, чтоли, ...  \n",
       "14409  [посмотрел, утомленных, солнцем, и, оказалось,...  \n",
       "14410  [крымотред, нарушает, правила, раздела, тк, в,...  \n",
       "14411  [до, сих, пор, пересматриваю, его, видео, орам...  \n",
       "\n",
       "[14412 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenization = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "train['clean_text_tk'] = train['clean_text'].apply(lambda x: tokenization.tokenize(x))\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96edb393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65926214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9329db5e",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "558bd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian'))\n",
    "def removing_stopwords(token):\n",
    "    return [w for w in token if not w.lower() in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7897499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tk</th>\n",
       "      <th>clean_text_st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>верблюдовто за что дебилы бл</td>\n",
       "      <td>[верблюдовто, за, что, дебилы, бл]</td>\n",
       "      <td>[верблюдовто, дебилы, бл]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>хохлы это отдушина затюканого россиянина мол в...</td>\n",
       "      <td>[хохлы, это, отдушина, затюканого, россиянина,...</td>\n",
       "      <td>[хохлы, это, отдушина, затюканого, россиянина,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>собаке  собачья смерть</td>\n",
       "      <td>[собаке, собачья, смерть]</td>\n",
       "      <td>[собаке, собачья, смерть]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>страницу обнови дебил это тоже не оскорбление ...</td>\n",
       "      <td>[страницу, обнови, дебил, это, тоже, не, оскор...</td>\n",
       "      <td>[страницу, обнови, дебил, это, оскорбление, до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>тебя не убедил  пдф в том что скрипалей отрави...</td>\n",
       "      <td>[тебя, не, убедил, пдф, в, том, что, скрипалей...</td>\n",
       "      <td>[убедил, пдф, скрипалей, отравила, россия, ана...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic  \\\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0   \n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0   \n",
       "2                          Собаке - собачья смерть\\n    1.0   \n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0   \n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                       верблюдовто за что дебилы бл   \n",
       "1  хохлы это отдушина затюканого россиянина мол в...   \n",
       "2                             собаке  собачья смерть   \n",
       "3  страницу обнови дебил это тоже не оскорбление ...   \n",
       "4  тебя не убедил  пдф в том что скрипалей отрави...   \n",
       "\n",
       "                                       clean_text_tk  \\\n",
       "0                 [верблюдовто, за, что, дебилы, бл]   \n",
       "1  [хохлы, это, отдушина, затюканого, россиянина,...   \n",
       "2                          [собаке, собачья, смерть]   \n",
       "3  [страницу, обнови, дебил, это, тоже, не, оскор...   \n",
       "4  [тебя, не, убедил, пдф, в, том, что, скрипалей...   \n",
       "\n",
       "                                       clean_text_st  \n",
       "0                          [верблюдовто, дебилы, бл]  \n",
       "1  [хохлы, это, отдушина, затюканого, россиянина,...  \n",
       "2                          [собаке, собачья, смерть]  \n",
       "3  [страницу, обнови, дебил, это, оскорбление, до...  \n",
       "4  [убедил, пдф, скрипалей, отравила, россия, ана...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['clean_text_st'] = train['clean_text_tk'].apply(lambda x : removing_stopwords(x))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d744d03",
   "metadata": {},
   "source": [
    "## Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59d6aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_word(tokenization):\n",
    "    return [wordnet_lemmatizer.lemmatize(token, pos=\"v\") for token in tokenization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "351a5250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                [верблюдовто, дебилы, бл]\n",
       "1        [хохлы, это, отдушина, затюканого, россиянина,...\n",
       "2                                [собаке, собачья, смерть]\n",
       "3        [страницу, обнови, дебил, это, оскорбление, до...\n",
       "4        [убедил, пдф, скрипалей, отравила, россия, ана...\n",
       "                               ...                        \n",
       "14407    [вонючий, совковый, скот, прибежал, ноет, стор...\n",
       "14408    [кого, любить, гоблина, тупорылого, чтоли, как...\n",
       "14409    [посмотрел, утомленных, солнцем, оказалось, эт...\n",
       "14410    [крымотред, нарушает, правила, раздела, тк, не...\n",
       "14411    [сих, пор, пересматриваю, видео, орамбо, кстат...\n",
       "Name: Text_Lemmatization, Length: 14412, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text_Lemmatization'] = train['clean_text_st'].apply(lambda x : lemmatize_word(x))\n",
    "train['Text_Lemmatization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2bd30eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    верблюдовто дебилы бл\n",
       "1        хохлы это отдушина затюканого россиянина мол в...\n",
       "2                                    собаке собачья смерть\n",
       "3        страницу обнови дебил это оскорбление доказанн...\n",
       "4        убедил пдф скрипалей отравила россия анализиро...\n",
       "                               ...                        \n",
       "14407    вонючий совковый скот прибежал ноет сторонник ...\n",
       "14408    кого любить гоблина тупорылого чтоли какуюнибу...\n",
       "14409    посмотрел утомленных солнцем оказалось это хор...\n",
       "14410    крымотред нарушает правила раздела тк нем обсу...\n",
       "14411    сих пор пересматриваю видео орамбо кстати свое...\n",
       "Name: Final_text, Length: 14412, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_text(list_of_text):\n",
    "    '''Takes a list of text and combines them into one large chunk of text.'''\n",
    "    combined_text = ' '.join(list_of_text)\n",
    "    return combined_text\n",
    "\n",
    "train['Final_text'] = train['Text_Lemmatization'].apply(lambda x : combine_text(x))\n",
    "train['Final_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb1d4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11421f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(train['Final_text'],train['toxic'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eeda630",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline(steps=[('cv',TfidfVectorizer()),('lr',LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6a3e3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv', TfidfVectorizer()), ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7351f977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192854665279223"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c14d17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_1 = Pipeline(steps=[('cv',CountVectorizer()),('lr',LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd6b1dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()), ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr_1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbe80f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446063128685397"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr_1.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3b9ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c026043",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_2 = Pipeline(steps=[('cv',CountVectorizer()),('lr',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e453a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()), ('lr', RandomForestClassifier())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr_2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af62f4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8015955601803677"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr_2.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a030105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3a244ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_3 = Pipeline(steps=[('cv',CountVectorizer()),('lr',SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5e4ef27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()), ('lr', SVC())])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr_3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4879576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991675338189386"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr_3.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2c06313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "pipeline_file = open(\"RU_toxic_classifier_model.pkl\",\"wb\")\n",
    "joblib.dump(pipe_lr_1,pipeline_file)\n",
    "pipeline_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb4106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e8854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
